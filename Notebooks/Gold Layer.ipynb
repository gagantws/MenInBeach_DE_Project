{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94d680ff-f3fa-41fd-9c26-f2c0f24c6066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setting Up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f57e56d3-7690-4694-9eaf-f075d8c9a0fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip uninstall -y databricks_helpers \n",
    "%pip install git+https://github.com/data-derp/databricks_helpers#egg=databricks_helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e6ee86d-3f94-410f-95cf-83ead1d6165f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "exercise_name = \"final_day_presentation\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c69f87-7abe-41c0-9a0c-5cd0326a57c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_helpers.databricks_helpers import DataDerpDatabricksHelpers\n",
    "\n",
    "helpers = DataDerpDatabricksHelpers(dbutils, exercise_name)\n",
    "\n",
    "current_user = helpers.current_user()\n",
    "working_directory = helpers.working_directory()\n",
    "\n",
    "print(f\"Your current working directory is: {working_directory}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e859d44-61fe-4361-b58f-451c9458b400",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read raw file from Bronze\n",
    "\n",
    "silver_layer_path = working_directory + \"/silver\"\n",
    "\n",
    "gold_df = spark\\\n",
    "    .read\\\n",
    "    .parquet(silver_layer_path)\n",
    "\n",
    "print(f\"Schema of the raw DataFrame:\")\n",
    "gold_df.printSchema()\n",
    "display(gold_df.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "600f5707-05a7-44e8-9ef8-b2bce5d71261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Questions:\n",
    "### 1. How do restaurant ratings and popularity (number of ratings) vary across different cities and localities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28adb511-3dad-4bd1-a575-51ae3be67c73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col, avg, sum, count, round, min, max\n",
    "import plotly.express as px\n",
    "\n",
    "def analyze_and_plot_city_performance(input_df):\n",
    "\n",
    "    # --- Calculations (Aggregation) ---\n",
    "    print(\" Performing city-level aggregation...\")\n",
    "    city_analysis = input_df.groupBy(\"City\").agg(\n",
    "        round(avg(\"Avg_rating\"), 2).alias(\"avg_city_rating\"),\n",
    "        round(avg(\"Total_ratings\")).alias(\"avg_city_popularity\"),\n",
    "        sum(\"Total_ratings\").alias(\"total_city_popularity\"),\n",
    "        count(\"*\").alias(\"total_restaurants_in_city\")\n",
    "    )\n",
    "\n",
    "    # ---  Display Results in Notebook ---\n",
    "    city_analysis_by_rating = city_analysis.orderBy(col(\"avg_city_rating\").desc())\n",
    "    city_analysis_by_popularity = city_analysis.orderBy(col(\"avg_city_popularity\").desc())\n",
    "\n",
    "     # Find the min and max for each column to be used in the score\n",
    "    min_max_values = city_analysis.agg(\n",
    "        min(\"avg_city_rating\").alias(\"min_rating\"),\n",
    "        max(\"avg_city_rating\").alias(\"max_rating\"),\n",
    "        min(\"avg_city_popularity\").alias(\"min_popularity\"),\n",
    "        max(\"avg_city_popularity\").alias(\"max_popularity\")\n",
    "    ).first()\n",
    "\n",
    "    min_rating = min_max_values[\"min_rating\"]\n",
    "    max_rating = min_max_values[\"max_rating\"]\n",
    "    min_popularity = min_max_values[\"min_popularity\"]\n",
    "    max_popularity = min_max_values[\"max_popularity\"]\n",
    "\n",
    "    # Normalize the columns to a 0-1 scale\n",
    "    df_normalized = city_analysis.withColumn(\"rating_score\",round((col(\"avg_city_rating\") - min_rating) / (max_rating - min_rating), 3)).withColumn(\n",
    "        \"popularity_score\",round((col(\"avg_city_popularity\") - min_popularity) / (max_popularity - min_popularity), 3))\n",
    "\n",
    "    # Define weights and calculate the final score\n",
    "    # Let's say rating is slightly more important than popularity\n",
    "    weight_rating = 0.6\n",
    "    weight_popularity = 0.4\n",
    "\n",
    "    df_with_score = df_normalized.withColumn(\"city_score\",round((col(\"rating_score\") * weight_rating) + (col(\"popularity_score\") * weight_popularity), 3))\n",
    "\n",
    "    # --- Display the final results ---\n",
    "    df_with_score.select(\"city\", \"avg_city_rating\", \"avg_city_popularity\",\"rating_score\", \"popularity_score\", \"city_score\", \"total_restaurants_in_city\").orderBy(col(\"city_score\").desc()).show()\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # Convert the aggregated Spark DataFrame to a Pandas DataFrame for plotting\n",
    "    pandas_df = df_with_score.toPandas()\n",
    "\n",
    "    # Sort cities by the overall score for a more insightful plot\n",
    "    pandas_df_sorted = pandas_df.sort_values(\"city_score\", ascending=False)\n",
    "\n",
    "    # Reshape the data from wide to long format for Plotly Express\n",
    "    df_melted = pandas_df.melt(\n",
    "        id_vars=['City', 'city_score'],\n",
    "        value_vars=['rating_score', 'popularity_score'],\n",
    "        var_name='metric_type',\n",
    "        value_name='normalized_score'\n",
    "    )\n",
    "\n",
    "    # Create the grouped bar chart\n",
    "    fig = px.bar(\n",
    "        df_melted,\n",
    "        x=\"City\",\n",
    "        y=\"normalized_score\",\n",
    "        color=\"metric_type\",  # Creates the groups for rating vs. popularity\n",
    "        barmode=\"group\",\n",
    "        title=\"Rating vs. Popularity Score by City\",\n",
    "        labels={\n",
    "            \"normalized_score\": \" Score (0 to 1)\",\n",
    "            \"City\": \"City\",\n",
    "            \"metric_type\": \"Metric\"\n",
    "        },\n",
    "        height=600  # Adjust height for better readability\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return city_analysis_by_rating, city_analysis_by_popularity, df_with_score\n",
    "\n",
    "city_restaurant_analysis = analyze_and_plot_city_performance(gold_df)\n",
    "display(city_restaurant_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a507bfed-f803-4296-962e-1657cc3c80b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5.What is the market share and performance of vegetarian vs. non-vegetarian restaurants in key areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bece939-7f45-42cd-98bf-8ff6e19bc6d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, sum, round, avg, when\n",
    "from pyspark.sql.window import Window\n",
    "import plotly.express as px\n",
    "\n",
    "def analyze_veg_nonveg_performance(input_df):\n",
    "\n",
    "    # Filter out rows where the 'Vegetarian' column is null\n",
    "    df_filtered = input_df.filter(col(\"Vegetarian\").isNotNull())\n",
    "\n",
    "    df_filtered = df_filtered.withColumn(\"Vegetarian\",when(col(\"Vegetarian\") == True, \"Veg\").otherwise(\"Non-Veg\"))\n",
    "\n",
    "    # --- 1. Market Share Calculation ---\n",
    "    veg_counts_city = df_filtered.groupBy(\"City\", \"Vegetarian\").agg(count(\"*\").alias(\"restaurant_count\"))\n",
    "    city_window = Window.partitionBy(\"City\")\n",
    "    city_market_share_df = veg_counts_city.withColumn(\"total_restaurants_in_city\",sum(\"restaurant_count\").over(city_window)).withColumn(\n",
    "        \"market_share_pct\",round((col(\"restaurant_count\") / col(\"total_restaurants_in_city\")) * 100, 2))\n",
    "\n",
    "    # --- 2. Performance Calculation ---\n",
    "    city_performance_df = df_filtered.groupBy(\"City\", \"Vegetarian\").agg(\n",
    "        round(avg(\"Avg_rating\"), 2).alias(\"avg_rating\"),\n",
    "        round(avg(\"Total_ratings\")).alias(\"avg_popularity_score\")\n",
    "    )\n",
    "\n",
    "    # First, convert the Spark DataFrame to a Pandas DataFrame\n",
    "    pandas_market_share = city_market_share_df.toPandas()\n",
    "    pandas_restaurant_performance = city_performance_df.toPandas()\n",
    "\n",
    "    # Create the grouped bar chart\n",
    "    market_share = px.bar(\n",
    "        pandas_market_share,\n",
    "        x=\"City\",\n",
    "        y=\"market_share_pct\",\n",
    "        color=\"Vegetarian\",  # This creates the \"Veg\" vs \"Non-Veg\" groups\n",
    "        barmode=\"group\",\n",
    "        title=\"Market Share of Veg vs. Non-Veg Restaurants by City\",\n",
    "        labels={\"market_share_pct\": \"Market Share (%)\", \"City\": \"City\", \"Vegetarian\": \"Restaurant Type\"}\n",
    "    )\n",
    "\n",
    "    market_share.show()\n",
    "\n",
    "    # First, convert the performance Spark DataFrame to a Pandas DataFrame\n",
    "    pandas_performance = performance_results.toPandas()\n",
    "\n",
    "    # Create the grouped bar chart for average rating\n",
    "    restaurant_performance = px.bar(\n",
    "        pandas_restaurant_performance,\n",
    "        x=\"City\",\n",
    "        y=\"avg_rating\",\n",
    "        color=\"Vegetarian\",\n",
    "        barmode=\"group\",\n",
    "        title=\"Performance (Average Rating) of Veg vs. Non-Veg Restaurants by City\",\n",
    "        labels={\"avg_rating\": \"Average Rating\", \"City\": \"City\", \"Vegetarian\": \"Restaurant Type\"},\n",
    "        color_discrete_sequence=px.colors.qualitative.Pastel, # Or D3, Plotly, Light, T10\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    restaurant_performance.show()\n",
    "\n",
    "    return city_market_share_df, city_performance_df\n",
    "\n",
    "# --- How to use the function ---\n",
    "# Assuming 'swiggy_df_transformed' is your cleaned input DataFrame\n",
    "market_share_results, performance_results = analyze_veg_nonveg_performance(gold_df)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
